<!DOCTYPE html>
<html>
<body style="background-color:#dbebf9">
<style>
div.a {

  margin: 25px 200px;
}


</style>
<br>
<br>
<br>
<br>
<h1 style="text-align:center; margin: 25px 200px;">Asking the Wrong Questions:<br></h1><h2 style="text-align:center; margin: 25px 200px;"> What I learned about cognitive science from a summer working on an Alexa Socialbot</h2>
<p style="text-align:center;">by Abraham Brauner</p>
<br>
<font size="+2"><div class="a">

<p>There is one question that everyone who studies cognitive science is tired of hearing.<br />
<br />
Sometimes it is asked by old high school friends, sometimes by fellow undergrads. It is often asked in interviews, and certain to be heard many times at family gatherings.</p>

<p><b>&ldquo;What is cognitive science?&rdquo;</b></p>

<p>You would think we would have a good answer to this question after hearing it so many times, but we don&rsquo;t. Often, intro to CogSci classes spend a whole lecture just trying to describe it. I have heard cognitive science explained as: <br />
&ldquo;Like psychology, but with computers.&rdquo;<br />
&ldquo;It&rsquo;s AI and stuff, right? Like artificial intelligence?&rdquo;<br />
&ldquo;It&rsquo;s basically neuroscience.&rdquo;<br />
&ldquo;It&rsquo;s what people who can&rsquo;t handle computer science do.&rdquo;</p>

<p>A Google search finds the definition: &ldquo;The study of thought, learning, and mental organization, which draws on aspects of psychology, linguistics, philosophy, and computer modeling.&rdquo; While this is basically true, it is too general to be a useful answer, and yet not even particularly comprehensive.<br />
I often quote a professor at my school (UCSD), who said: &ldquo;cognitive science is the idea that the human brain is like a computer, built by evolution, and programmed by experience.&rdquo; I recite this not because it is a useful explanation, but because it sounds really cool. It doesn&rsquo;t really mean anything.</p>

<p>So what is cognitive science really? Is it an unnecessary conglomeration of fields? Is it, as some say, just a place to put the losers who can&rsquo;t handle computer science?</p>

<p>These are the wrong questions. We should not be asking &ldquo;What is cognitive science?&rdquo;, but instead &ldquo;What is cognitive science useful for?&rdquo;</p>

<p>On a broad level, cognitive science is really good at making connections between things. This could be something like understanding how people control their bodies, and using that knowledge to help build better prosthetic limbs. It could be watching people cross the street, in order to design autonomous cars that can effectively communicate with pedestrians. Or it could be applying animal foraging theory to build a website with good information scent. </p>

<p>But most of all, cognitive science is good at asking the right questions. Computer science is about <i>how</i> to build things, but cognitive science determines <i>what</i> to build. This was something I discovered over my career as an undergrad, but it became most apparent last summer, when I interned at UCSC, working on an Alexa Prize Socialbot. <br />

<p>The Alexa Prize was a competition hosted by Amazon, whereby select universities put together teams to work on an Alexa Socialbot, the goal being to create a machine that could sustain a casual conversation with a human for 10 minutes that would meet customer satisfaction thresholds. </p>

<p>Although I only worked on a small corner of the project, part of my role consisted of chatting with the Socialbot to find errors, and I came to understand its patterns quite well. And while it could be kinda nifty, the fact of the matter was that the socialbot was useless. Not only was it frustrating when the bot failed to understand my speech, it also had nothing interesting to contribute. It couldn&rsquo;t carry a conversation topic, and would frequently default to &ldquo;What would you like to talk about now?&rdquo; Whenever it did say something, it would be some random internet fact. If you got really lucky, it would use a feature I helped create, whereby it would speak the text of Reddit posts, which might be a bit amusing. But overall, it was still much less interesting than just going on Reddit yourself.</p>

<p>So where did we go wrong with the socialbot? I remember a discussion we had about how to construct phrases for Alexa. The question was: should we have the phrases be casual or have proper grammar? We decided to have proper grammar, in order to encourage users to speak formally, which is easier for Alexa to parse. </p>

<p>We also discussed what topics Alexa should be conversant about. The whole project was organized around a bunch of topics that Alexa should be able to have conversations about, and part of my role consisted of finding new topics. The question was, what topics would make sense to have?</p>

<p><b>But we were asking the wrong questions.</b></p>

<p> Design should always begin with observation, which in this case shoud be observing people having conversations. The right questions are: What are people like when they have conversations? What do they say? How do they say it? How does the context play in? </p>

<p>The Alexa Prize needed cognitive science. Though the socialbot knew how to listen and talk, it didn&rsquo;t know what to say. While it is still unclear if it is even possible to create a socialbot that holds interesting, meaningful conversation with humans, it certainly is impossible if you ask the wrong questions. </p>

<p>With better observations and research, we would begin to understand how conversation really works, and from there begin to build the socialbot. Instead of looking for more topics or phrases to expand its conversational repertoire, we would figure out how to build context for the conversation, and know what, when, and how people say things.</p>

<p>This is what cognitive science is good for. It is an approach to problem solving, the idea that we can build effective solutions only after we understand the context of the problem. Without cognitive science, you wind up asking the wrong questions, and when you ask the wrong questions, you wind up with a socialbot that is nothing more than a useless gimmick.<br />
</p>

</font>
</body>
</html>
